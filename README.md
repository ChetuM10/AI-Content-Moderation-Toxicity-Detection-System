<div align="center">

# 🛡️ Senti-Clean
## AI-Powered Content Moderation & Toxicity Detection System

**Developed by Chetan ([@ChetuM10](https://github.com/ChetuM10))**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Flask](https://img.shields.io/badge/flask-2.0+-green.svg)](https://flask.palletsprojects.com/)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

</div>

---

## 🚀 Overview

**Senti-Clean** is a production-ready web application for real-time toxicity detection and content moderation powered by transformer-based machine learning models and AI-driven text rewriting capabilities.

Unlike traditional toxicity detectors, Senti-Clean not only **identifies** harmful content but also provides **AI-powered alternatives** to rewrite toxic text into constructive feedback using Groq's Llama 3.1 API.

### Key Features

- ⚡ **Real-Time Detection** - Analyze text in under 3 seconds
- 🎯 **High Accuracy** - 92%+ toxicity classification using BERT/RoBERTa
- 🤖 **AI Rewriting** - Automatically neutralize toxic content with Groq API
- 📊 **Sentiment Analysis** - Advanced emotion detection with TextBlob
- 🎨 **Modern UI** - Clean, responsive web interface
- 🔒 **Production Ready** - Flask backend with error handling

---

## 📸 Demo

![Senti-Clean Interface](screenshot.png)

**Try it yourself:**
